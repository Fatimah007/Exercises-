{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fatimah007/Exercises-/blob/main/Copy_of_Bagging_Exercise_e.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ae4cc02",
      "metadata": {
        "id": "9ae4cc02"
      },
      "source": [
        "# Bagging Exercise\n",
        "\n",
        "In this exercise, you will explore the concept of Bagging (Bootstrap Aggregating) and implement it using a random forest model. Bagging is an ensemble technique mainly used for reducing the variance of a predictive model and preventing overfitting. The main idea behind bagging is to combine multiple learners in a way that the ensemble model performs better than an individual model.\n",
        "\n",
        "## Dataset\n",
        "We will use the Iris dataset for this exercise. The Iris dataset is a classic dataset from the field of machine learning, containing measurements for iris flowers of three different species. **Feel free to use another dataset!!**\n",
        "\n",
        "## Task\n",
        "Your task is to:\n",
        "1. Load the dataset.\n",
        "2. Preprocess the data (if necessary).\n",
        "3. Implement Bagging models.\n",
        "4. Evaluate the models performance.\n",
        "\n",
        "Please fill in the following code blocks to complete the exercise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cd906704",
      "metadata": {
        "id": "cd906704"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bc0f20e",
      "metadata": {
        "id": "3bc0f20e"
      },
      "source": [
        "# Load the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "47ecb305",
      "metadata": {
        "id": "47ecb305",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation',\n",
        "           'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
        "data = pd.read_csv(url, header=None, names=columns, na_values=' ?')\n",
        "\n",
        "# Handle missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# Split the data into features and target variable\n",
        "X = data.drop('income_ >50K', axis=1)\n",
        "y = data['income_ >50K']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0e69164",
      "metadata": {
        "id": "c0e69164"
      },
      "source": [
        "# Preprocess the data (if necessary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2104eb8e",
      "metadata": {
        "id": "2104eb8e"
      },
      "source": [
        "# Split the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f3a3d4e9",
      "metadata": {
        "id": "f3a3d4e9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdcb9a0a",
      "metadata": {
        "id": "bdcb9a0a"
      },
      "source": [
        "# Initialize and Train the Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea773220",
      "metadata": {
        "id": "ea773220"
      },
      "source": [
        "## Random Forest\n",
        "Initialize and train a Random Forest classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3e29fd42",
      "metadata": {
        "id": "3e29fd42"
      },
      "outputs": [],
      "source": [
        "# Initialize and train the Random Forest classifier\n",
        "random_forest_classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "random_forest_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = random_forest_classifier.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb3a2438",
      "metadata": {
        "id": "fb3a2438"
      },
      "source": [
        "### Evaluate the model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "38d965b4",
      "metadata": {
        "id": "38d965b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e3dcbf-41b1-4c77-afa2-0c533b9728e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Accuracy: 85.18%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Random Forest Model Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ef4327",
      "metadata": {
        "id": "27ef4327"
      },
      "source": [
        "## Bagging Meta-estimator\n",
        "Initialize a K-Nearest Neighbors classifier and use it as the base estimator for the Bagging classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d3a43f7f",
      "metadata": {
        "id": "d3a43f7f"
      },
      "outputs": [],
      "source": [
        "# Initialize base classifier and Bagging Meta-estimator\n",
        "base_estimator = KNeighborsClassifier()\n",
        "bagging_classifier = BaggingClassifier(base_estimator, n_estimators=50, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = bagging_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b8db1eb",
      "metadata": {
        "id": "1b8db1eb"
      },
      "source": [
        "### Evaluate the model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8697dc13",
      "metadata": {
        "id": "8697dc13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499c149d-0409-4264-e2f5-eada94bfb1b3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bagging Classifier Model Accuracy: 77.29%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Bagging Classifier Model Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8768d05e",
      "metadata": {
        "id": "8768d05e"
      },
      "source": [
        "## Pasting\n",
        "Initialize a Decision Tree classifier and use it as the base estimator for a Bagging classifier with Pasting (without replacement)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ee558a9",
      "metadata": {
        "id": "2ee558a9"
      },
      "outputs": [],
      "source": [
        "# Initialize the base classifier and Bagging Meta-estimator with Pasting\n",
        "base_estimator = DecisionTreeClassifier()\n",
        "pasting_classifier = BaggingClassifier(base_estimator, n_estimators=50, max_samples=0.7, bootstrap=False, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "pasting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = pasting_classifier.predict(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ff8b204",
      "metadata": {
        "id": "4ff8b204"
      },
      "source": [
        "### Evaluate the model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fd5abd3",
      "metadata": {
        "id": "2fd5abd3"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Pasting Classifier Model Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dcdb581",
      "metadata": {
        "id": "1dcdb581"
      },
      "source": [
        "## Roughly Balanced Bagging (RBB)\n",
        "Implement Roughly Balanced Bagging by manually creating balanced bootstrap samples and aggregating predictions from multiple Decision Tree classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21309157",
      "metadata": {
        "id": "21309157"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Number of base estimators\n",
        "n_estimators = 100\n",
        "\n",
        "# Initialize arrays to store the ensemble predictions and models\n",
        "ensemble_preds = np.zeros((n_estimators, len(X_test)))\n",
        "ensemble_models = []\n",
        "\n",
        "for i in range(n_estimators):\n",
        "    # Create a bootstrap sample, ensuring it's roughly balanced\n",
        "    pos_indices = np.where(y_train == 1)[0]\n",
        "    neg_indices = np.where(y_train == 0)[0]\n",
        "\n",
        "    chosen_pos_indices = np.random.choice(pos_indices, size=len(pos_indices), replace=True)\n",
        "    chosen_neg_indices = np.random.choice(neg_indices, size=len(pos_indices), replace=True)\n",
        "\n",
        "    balanced_sample_indices = np.concatenate([chosen_pos_indices, chosen_neg_indices])\n",
        "    np.random.shuffle(balanced_sample_indices)\n",
        "\n",
        "    X_train_balanced = X_train.iloc[balanced_sample_indices]\n",
        "    y_train_balanced = y_train.iloc[balanced_sample_indices]\n",
        "\n",
        "    # Train a decision tree classifier on the balanced bootstrap sample\n",
        "    tree_clf = DecisionTreeClassifier(random_state=i)\n",
        "    tree_clf.fit(X_train_balanced, y_train_balanced)\n",
        "    ensemble_models.append(tree_clf)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    ensemble_preds[i] = tree_clf.predict(X_test)\n",
        "\n",
        "# Majority voting across all estimators for the final prediction\n",
        "final_preds = np.round(np.mean(ensemble_preds, axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee97138e",
      "metadata": {
        "id": "ee97138e"
      },
      "source": [
        "### Evaluate the model performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3726ae5",
      "metadata": {
        "id": "c3726ae5"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, final_preds)\n",
        "print(f'Roughly Balanced Bagging Model Accuracy: {accuracy:.2f}')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}